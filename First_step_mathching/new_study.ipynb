{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO MAKE The connections to all but with a size differnce\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "from datetime import datetime\n",
    "from machine.mlp import MyModel\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Set up the file paths\n",
    "curpath = r'C:\\Users\\abelt\\OneDrive\\Dokumenter\\GitHub\\Ship_datafusion\\First_step_mathching'\n",
    "folderpath = os.path.join(curpath, 'frames')\n",
    "os.makedirs(folderpath, exist_ok=True)\n",
    "\n",
    "# Clear folder for frames\n",
    "def clear_folder(folder = folderpath):\n",
    "    os.makedirs(folderpath, exist_ok=True)\n",
    "    # Directory for saving frames, and cleaning it every run\n",
    "    for item in os.listdir(folder):\n",
    "        os.remove(os.path.join(folderpath, item))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward with heading\n",
    "def forward(t1, t2, model):\n",
    "    e1 = model(torch.tensor(t1, dtype=torch.float32))\n",
    "    e2 = model(torch.tensor(t2, dtype=torch.float32))\n",
    "    return torch.cdist(e1,e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAY AREA:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set up model and optimizer\n",
    "    maxiter = 300\n",
    "    N = 250s\n",
    "    N_test = 50\n",
    "    sigma_distance = 0.025\n",
    "    sigma_heading = 0.005\n",
    "    encode = True\n",
    "    missing_percentage = 0.6\n",
    "\n",
    "    ranks = [1, 3, 5]\n",
    "\n",
    "    mlp_params = {\n",
    "        'input_dim': 4,\n",
    "        'hidden_dim': 1024,\n",
    "        'output_dim': 254,\n",
    "        'n_layers': 5,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.00001,\n",
    "    }\n",
    "\n",
    "    # Directory for saving frames, and cleaning it every run\n",
    "    curpath = r'C:\\Users\\abelt\\OneDrive\\Dokumenter\\GitHub\\Ship_datafusion\\First_step_mathching'\n",
    "    folderpath = os.path.join(curpath, 'frames')\n",
    "    \n",
    "    clear_folder(folder=folderpath)\n",
    "\n",
    "    # Initialize variables\n",
    "    frames = []\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    # Create empty lists to store accuracies\n",
    "    rank_accuracies = {rank: [] for rank in ranks}\n",
    "\n",
    "    # Generate validation data\n",
    "    p1, p2 = generate_data(N_test, sigma=sigma_distance)\n",
    "    t1, t2 = calculate_heading(p1,p2, encoding=encode, missing_percentage=missing_percentage)\n",
    "    \n",
    "    model = MyModel(input_dim=mlp_params['input_dim'], hidden_dim=mlp_params['hidden_dim'], \n",
    "                output_dim=mlp_params['output_dim'], depth=mlp_params['n_layers'], \n",
    "                drop_prob=mlp_params['dropout'])\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=mlp_params['learning_rate'])\n",
    "    # Training loop\n",
    "    for i in range(maxiter + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        p1t, p2t = generate_data(N, sigma=sigma_distance)\n",
    "        t1p, t2p = calculate_heading(p1t,p2t, encoding=encode, missing_percentage=missing_percentage)\n",
    "        \n",
    "        diag_matrix = forward(t1p, t2p, model)\n",
    "        \n",
    "        # Calculate training loss and backpropagate\n",
    "        diag = torch.diag(diag_matrix)\n",
    "        train_loss = torch.sum(diag)\n",
    "        train_loss.backward()\n",
    "        losses['train'].append(train_loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            #diag_matrix_val = forward(p1, p2, model)\n",
    "            diag_matrix_val = forward(t1, t2, model)\n",
    "\n",
    "            diag_val = torch.diag(diag_matrix_val)\n",
    "            val_loss = torch.sum(diag_val)\n",
    "            losses['val'].append(val_loss.item())\n",
    "\n",
    "        # Plot and save frame every 10 iterations\n",
    "        if i % 10 == 0 or i == 1: # and i > 0\n",
    "            # Rank-N evaluation\n",
    "            for rank in ranks:\n",
    "                accuracy = evaluate_rankN(diag_matrix, rank)\n",
    "                rank_accuracies[rank].append(accuracy.item())\n",
    "\n",
    "            d = torch.argmin(diag_matrix_val, dim=1).detach().numpy()\n",
    "\n",
    "            # Plotting\n",
    "            fig, (ax1, ax2, ax3) = plot_iteration_with_loss_and_accuracy(\n",
    "                t1, t2, diag_matrix_val, np.arange(N_test), losses, rank_accuracies, train_loss.item(), i, maxiter\n",
    "            )\n",
    "            frame_path = os.path.join(folderpath, f'frame_{i}.png')\n",
    "            fig.savefig(frame_path)\n",
    "            frames.append(imageio.imread(frame_path))\n",
    "            plt.close(fig)\n",
    "\n",
    "    # Save the video\n",
    "    imageio.mimsave(os.path.join(folderpath, '0_training_epochs.mp4'), frames, fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Lav det med AIS data og SAR data som \"Test data\".\n",
    "- Lav en tabel hvor der ændres på forskellige parametre: sigma, N og N_features (Her skal cog og sog regnes med)\n",
    "- Tilføj cog og sog i generatoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_headings(p1, p2, headings):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(0, 1)\n",
    "    # Plot the points\n",
    "    ax.scatter(p1[0], p1[1], c='b', label=\"Track 1\", s=5)\n",
    "    ax.scatter(p2[0], p2[1], c='r', label=\"Track 2\", s=5)\n",
    "    \n",
    "    # Plot connections\n",
    "    for i in range(len(p1[0])):\n",
    "        ax.plot([p1[0][i], p2[0][i]], [p1[1][i], p2[1][i]], 'g-')\n",
    "\n",
    "    # Plot arrows to indicate heading\n",
    "    dx = np.cos(headings)*0.05  # x component of the direction\n",
    "    dy = np.sin(headings)*0.05 # y component of the direction\n",
    "    ax.quiver(p1[0], p1[1], dx, dy, angles='xy', scale_units='xy', scale=1, color='purple', width=0.003)\n",
    "\n",
    "    # Add legend and display the plot\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "N = 5\n",
    "sigma = 0.075\n",
    "p1, p2 = generate_data(N, sigma)\n",
    "h1, h2 = calculate_heading(p1, p2, degrees=False, sigma=0.05)\n",
    "plot_with_headings(p1, p2, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_heading = 0  # in degrees, representing the direction (0,0) to (1,0)\n",
    "std_dev = 15  # standard deviation in degrees\n",
    "num_samples = 1000  # number of samples to simulate\n",
    "\n",
    "# Generate heading samples from a normal distribution centered at 0 degrees\n",
    "headings = np.random.normal(mean_heading, std_dev, num_samples)\n",
    "# Adjust heading values to wrap around the unit circle (0 to 360 degrees)\n",
    "headings = np.mod(headings, 360)\n",
    "# Generate x and y coordinates based on the heading angles on the unit circle\n",
    "x_coords = np.cos(np.radians(headings))\n",
    "y_coords = np.sin(np.radians(headings))\n",
    "\n",
    "\n",
    "\n",
    "# Plot the histogram of the adjusted heading distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(headings, bins=30, color='lightcoral', edgecolor='black', density=True)\n",
    "plt.xlabel(\"Heading (degrees)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.title(\"Simulated Heading Distribution Aligned with Direction (0,0) to (1,0)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the unit circle with simulated heading vectors\n",
    "plt.figure(figsize=(8, 8))\n",
    "# Plot the unit circle boundary\n",
    "theta = np.linspace(0, 2 * np.pi, 1000) \n",
    "plt.plot(np.cos(theta), np.sin(theta), label='Unit Circle')\n",
    "\n",
    "# Plot the heading vectors as points on the unit circle\n",
    "plt.scatter(x_coords, y_coords, color='lightcoral',marker='o', alpha=0.7, s=30, label='Simulated Headings')\n",
    "\n",
    "# Add axes and labels\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Simulated Heading Distribution on Unit Circle')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "# # -*- coding: utf-8 -*-\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import imageio.v2 as imageio\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "# from machine.mlp import MyModel\n",
    "# import matplotlib.animation as animation\n",
    "\n",
    "# # Normalize the data (optional)\n",
    "# def normalize(data):\n",
    "#     min_val = np.min(data)\n",
    "#     max_val = np.max(data)\n",
    "#     return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "# # Generate synthetic data\n",
    "# def generate_data(N, sigma):\n",
    "#     np.random.seed(1)\n",
    "#     g = np.random.Generator(np.random.PCG64())\n",
    "#     x = g.uniform(0, 1, N)\n",
    "#     y = g.uniform(0, 1, N)\n",
    "#     x1 = np.clip(g.normal(x, sigma), a_min=0, a_max=1)  \n",
    "#     y1 = np.clip(g.normal(y, sigma), a_min=0, a_max=1)\n",
    "#     track1 = np.stack((x, y))\n",
    "#     track2 = np.stack((x1, y1))\n",
    "#     return track1, track2\n",
    "\n",
    "# # Plot points\n",
    "# def plot_tracks(track1, track2):\n",
    "#     fig, ax = plt.subplots(dpi=100)\n",
    "#     ax.scatter(track1[0], track1[1], c='b', marker='o', label=\"Track 1\")\n",
    "#     ax.scatter(track2[0], track2[1], c='r', marker='x', label=\"Track 2\")\n",
    "#     ax.legend()\n",
    "#     return fig, ax\n",
    "\n",
    "# # Plot connections with dynamic line width\n",
    "\n",
    "# def plot_connection(ax, track1, track2, assignment, **kwargs):\n",
    "#     for i, j in enumerate(assignment):\n",
    "#         t1 = track1.T[i]\n",
    "#         t2 = track2.T[j]\n",
    "#         #dist = np.linalg.norm(t1 - t2)\n",
    "#         ax.plot([t1[0], t2[0]], [t1[1], t2[1]],  **kwargs)#linewidth=2.5/(dist + 1e-5),\n",
    "\n",
    "# def plot_loss(losses):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(losses)\n",
    "#     ax.set_title(\"Training Loss Over Iterations\")\n",
    "#     ax.set_xlabel(\"Iterations\")\n",
    "#     ax.set_ylabel(\"Loss\")\n",
    "\n",
    "#     plt.show()\n",
    "#     return fig, ax\n",
    "\n",
    "# # Set up model and optimizer\n",
    "# mlp_params = {\n",
    "#     'input_dim': 2,\n",
    "#     'hidden_dim': 1024,\n",
    "#     'output_dim': 254,\n",
    "#     'n_layers': 2,\n",
    "#     'dropout': 0.1,\n",
    "# }\n",
    "# model = MyModel(input_dim=mlp_params['input_dim'], hidden_dim=mlp_params['hidden_dim'], \n",
    "#                 output_dim=mlp_params['output_dim'], depth=mlp_params['n_layers'], \n",
    "#                 drop_prob=mlp_params['dropout'])\n",
    "\n",
    "# model.train()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "# # Directory for saving frames, and cleaning it every run\n",
    "# curpath = r'C:\\Users\\abelt\\OneDrive\\Dokumenter\\GitHub\\Ship_datafusion\\First_step_mathching'\n",
    "# folderpath = os.path.join(curpath, 'frames')\n",
    "# os.makedirs(folderpath, exist_ok=True)\n",
    "# for item in os.listdir(folderpath):\n",
    "#     os.remove(os.path.join(folderpath, item))\n",
    "\n",
    "# # Initialize variables\n",
    "# frames = []\n",
    "# losses = []\n",
    "# N = 25\n",
    "# sigma = 0.05\n",
    "# track1, track2 = generate_data(N, sigma)\n",
    "\n",
    "# # Training loop\n",
    "# for i in range(10000):\n",
    "#     optimizer.zero_grad()\n",
    "#     t1 = torch.tensor(track1.T, dtype=torch.float32)\n",
    "#     t2 = torch.tensor(track2.T, dtype=torch.float32)\n",
    "#     e1 = model(t1)\n",
    "#     e2 = model(t2)\n",
    "\n",
    "#     diag_matrix = torch.cdist(e1, e2)\n",
    "#     diag = torch.diag(diag_matrix)\n",
    "#     loss = torch.sum(diag)\n",
    "#     loss.backward()\n",
    "#     losses.append(loss.item())\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     # Plot and save frame every 10 iterations\n",
    "#     if i % 10 == 0:\n",
    "#         fig, ax = plot_tracks(track1, track2)\n",
    "#         plot_connection(ax, track1, track2, np.arange(N), color='g')\n",
    "#         d = torch.argmin(diag_matrix, dim=1).detach().numpy()\n",
    "#         plot_connection(ax, track1, track2, d, color='r')\n",
    "    \n",
    "#         ax.set_title(f\"Iteration: {i}\")\n",
    "\n",
    "#         frame_path = os.path.join(folderpath, f'frame_{i}.png')\n",
    "#         fig.savefig(frame_path)\n",
    "#         frames.append(imageio.imread(frame_path))\n",
    "#         plt.close(fig)\n",
    "\n",
    "\n",
    "# # Save the video\n",
    "# imageio.mimsave(os.path.join(folderpath, '0_training_epochs.mp4'), frames, fps=5)\n",
    "\n",
    "# def plot_loss(losses):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(losses)\n",
    "#     ax.set_title(\"Training Loss Over Iterations\")\n",
    "#     ax.set_xlabel(\"Iterations\")\n",
    "#     ax.set_ylabel(\"Loss\")\n",
    "\n",
    "#     plt.show()\n",
    "#     return fig, ax\n",
    "    \n",
    "# # Plot the loss curve\n",
    "# plot_loss(losses)\n",
    "\n",
    "\n",
    "\n",
    "# def plot_iteration_with_loss_and_accuracy(p1, p2, diag_matrix, green_indices, losses, rank_accuracies, loss, iteration, max_iter):\n",
    "#     \"\"\"\n",
    "#     Creates a subplot with the track plot on top, the loss curve in the bottom left, and the rank-N accuracy curve in the bottom right.\n",
    "\n",
    "#     Parameters:\n",
    "#         p1 (ndarray): Points for the first track, shape (2, N).\n",
    "#         p2 (ndarray): Points for the second track, shape (2, N).\n",
    "#         diag_matrix (ndarray): Diagonal matrix of the distance matrix.\n",
    "#         green_indices (array-like): Indices for green connections (e.g., correct matches).\n",
    "#         losses (list of float): List of loss values over training iterations.\n",
    "#         rank_accuracies (dict of lists): Dictionary where keys are rank values and values are lists of accuracy values over iterations.\n",
    "#         loss (float): Loss value for the current iteration.\n",
    "#         iteration (int): Current iteration number.\n",
    "#         max_iter (int): Maximum number of iterations.\n",
    "        \n",
    "#     Returns:\n",
    "#         fig (Figure): The matplotlib figure object containing all three subplots.\n",
    "#         (ax1, ax2, ax3): Tuple of axes objects for the track, loss, and accuracy plots.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Create a figure and a GridSpec layout for custom positioning\n",
    "#     fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "#     gs = fig.add_gridspec(2, 2, height_ratios=[3, 1], hspace=0.4, wspace=0.3)\n",
    "    \n",
    "#     # Top plot: Track connections (spanning both columns)\n",
    "#     ax1 = fig.add_subplot(gs[0, :])\n",
    "#     ax1.scatter(p1[0], p1[1], c='b', marker='o', label=\"Track 1\")\n",
    "#     ax1.scatter(p2[0], p2[1], c='r', marker='x', label=\"Track 2\")\n",
    "#     # Actual connection\n",
    "#     plot_connection(ax1, p1, p2, green_indices, color='g')\n",
    "    \n",
    "#     # MLP connection\n",
    "#     d = torch.argmin(diag_matrix, dim=1).detach().numpy()\n",
    "#     plot_connection(ax1, p1, p2, d, color='r')\n",
    "#     # Heading\n",
    "#     plot_direction_vectors(ax1, p1, p2, color1='blue', color2='red', width=0.003)\n",
    "#     ax1.set_title(f\"Iteration: {iteration}, Loss: {loss:.4f}\")\n",
    "#     ax1.legend(loc='upper left', bbox_to_anchor=(1.009, 1), fancybox=True, shadow=True)\n",
    "\n",
    "#     # Bottom left plot: Loss curve\n",
    "#     ax2 = fig.add_subplot(gs[1, 0])\n",
    "#     #ax2.plot(losses, label=\"Training Loss\", color='b')\n",
    "#     ax2.plot(losses['train'], label=\"Training Loss\", color='b')\n",
    "#     ax2.plot(losses['val'], label=\"Validation Loss\", color='orange', linestyle='--')\n",
    "#     ax2.set_xlim(0, max_iter + 1)\n",
    "#     ax2.set_title(\"Training Loss Over Iterations\")\n",
    "#     ax2.set_xlabel(\"Iterations\")\n",
    "#     ax2.set_ylabel(\"Loss\")\n",
    "#     ax2.legend(loc='upper right', fancybox=True, shadow=True)\n",
    "\n",
    "#     # Bottom right plot: Rank accuracy curves\n",
    "#     ax3 = fig.add_subplot(gs[1, 1])\n",
    "#     for rank, accuracies in rank_accuracies.items():\n",
    "#         ax3.plot(range(len(accuracies)), accuracies, label=f'Rank {rank}',  marker='o', linestyle='dashed')\n",
    "#     ax3.set_xlim(0, (max_iter + 1) / 10)\n",
    "#     ax3.set_ylim(0, 1)\n",
    "#     ax3.set_title(\"Rank-N Accuracy Over Iterations\")\n",
    "#     ax3.set_xlabel(\"Iterations, [i/10]\")\n",
    "#     ax3.set_ylabel(\"Accuracy\")\n",
    "#     ax3.legend(loc='upper left', bbox_to_anchor=(1.02, 1), fancybox=True, shadow=True)\n",
    "    \n",
    "#     return fig, (ax1, ax2, ax3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafusion_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
