{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Matching libaries\n",
    "import numpy as np\n",
    "\n",
    "# Plot libraries\n",
    "import folium\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scripts.data_loader import DataLoader\n",
    "from scripts.data_formatter import DataProcessor as dp\n",
    "from scripts.matching import hungarian_method\n",
    "from scripts.plotter import Plotter as pl\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d%m_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DOS\n",
    "Sort data for longest axis is length and shortest is height. Since the ship is always a rectangle and not a cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date and time filter\n",
    "date_key = '03-11-2022'\n",
    "# Define paths\n",
    "base_path = \"C:\\\\Users\\\\abelt\\\\OneDrive\\\\Desktop\\\\Kandidat\\\\\"\n",
    "## File names ##\n",
    "# AIS\n",
    "ais_files = {\n",
    "    '02-11-2022': 'ais\\\\ais_110215.csv',\n",
    "    '03-11-2022': 'ais\\\\ais_110315.csv',\n",
    "    '05-11-2022': 'ais\\\\ais_1105.csv'\n",
    "}\n",
    "# SAR\n",
    "sar_files = {\n",
    "    '02-11-2022': 'sar\\\\Sentinel_1_detection_20221102T1519.json',\n",
    "    '03-11-2022': 'sar\\\\Sentinel_1_detection_20221103T154515.json',\n",
    "    '05-11-2022': 'sar\\\\Sentinel_1_detection_20221105T162459.json'\n",
    "}\n",
    "# Norsat\n",
    "norsat_files = {\n",
    "    '02-11-2022': 'norsat\\\\Norsat3-N1-JSON-Message-DK-2022-11-02T151459Z.json',\n",
    "    '03-11-2022': 'norsat\\\\Norsat3-N1-JSON-Message-DK-2022-11-03T152759Z.json',\n",
    "    '05-11-2022': 'norsat\\\\Norsat3-N1-JSON-Message-DK-2022-11-05T155259Z.json'\n",
    "}\n",
    "\n",
    "data_loader = DataLoader(base_path = base_path, ais_files = ais_files, sar_files = sar_files, norsat_files = norsat_files, date_key = date_key)\n",
    "ais_data, sar_data, norsat_data = data_loader.load_data()\n",
    "\n",
    "\n",
    "# print('Interpolation for ais')\n",
    "# print('SAR')\n",
    "# ais_sar_interpol, sar_missing = dp.ais_interpolate_mmsi_points(ais_data = ais_data['tm_ais_sar'], date_key = date_key, interpolation_time_col = sar_data['sar_landmasked']['TimeStamp'])\n",
    "# print('Norsat-3')\n",
    "# ais_norsat_interpol, norsat_missing = dp.ais_interpolate_mmsi_points(ais_data = ais_data['tm_ais_norsat'], date_key = date_key, interpolation_time_col = norsat_data[date_key]['TimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCHING\n",
    "\n",
    "# Hungarian # \n",
    "########## Haversine ##########\n",
    "\n",
    "########## Nearest Neighbor Matching ##########\n",
    "\n",
    "def match_ships_to_norsat_nearest_neighbor(ship_dict, norsat_data):\n",
    "    all_matches = []\n",
    "    \n",
    "    # Iterate over each ship in the dictionary\n",
    "    for mmsi, coords in ship_dict.items():\n",
    "        ship_lat, ship_lon = coords['y'], coords['x']\n",
    "        nearest = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        # Iterate over each row in the norsat dataframe\n",
    "        for _, norsat_row in norsat_data.iterrows():\n",
    "            norsat_lat, norsat_lon, norsat_idx = norsat_row['latitude'], norsat_row['longitude'], norsat_row['norsat_id']\n",
    "            \n",
    "            # Calculate haversine distance\n",
    "            distance = haversine(ship_lat, ship_lon, norsat_lat, norsat_lon)\n",
    "            \n",
    "            # Check if this NORSAT point is closer than the current nearest\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                nearest = {\n",
    "                    'mmsi': mmsi,\n",
    "                    'ais_lat': ship_lat,\n",
    "                    'ais_lon': ship_lon,\n",
    "                    'norsat_lat': norsat_lat,\n",
    "                    'norsat_lon': norsat_lon,\n",
    "                    'norsat_distance_km': distance,\n",
    "                    'norsat_id': norsat_idx  # Include the index of the NORSAT row\n",
    "                }\n",
    "        \n",
    "        # If a nearest match was found, add it to the results\n",
    "        if nearest :\n",
    "            all_matches.append(nearest )\n",
    "    \n",
    "    return pd.DataFrame(all_matches)\n",
    "\n",
    "########## SAR ##########\n",
    "# Function to find two nearest matches for each AIS point\n",
    "def two_nearest_neighbors(ais_data, sar_data):\n",
    "    matches = []\n",
    "\n",
    "    # Iterate over each AIS point in the dictionary\n",
    "    for mmsi, coords in ais_data.items():\n",
    "        ais_lat, ais_lon = coords['y'], coords['x']\n",
    "        \n",
    "        # Create a list to store distances to all SAR points\n",
    "        sar_distances = []\n",
    "        \n",
    "        # Calculate distance to all SAR points and store them\n",
    "        for _, sar_row in sar_data.iterrows():\n",
    "            sar_lat, sar_lon, sar_idx = sar_row['latitude'], sar_row['longitude'], sar_row['sar_id']\n",
    "            distance = haversine(ais_lat, ais_lon, sar_lat, sar_lon)\n",
    "            sar_distances.append((distance, sar_idx, sar_lat, sar_lon))\n",
    "        \n",
    "        # Sort distances to find the two smallest ones\n",
    "        sar_distances.sort(key=lambda x: x[0])  # Sort by distance (first element of tuple)\n",
    "        \n",
    "        nearest = sar_distances[0]\n",
    "        second_nearest = sar_distances[1]\n",
    "            \n",
    "            # Append both matches to the results\n",
    "        matches.append({\n",
    "                'mmsi': mmsi,\n",
    "                'ais_lat': ais_lat,\n",
    "                'ais_lon': ais_lon,\n",
    "                'sar_id' : nearest[1],\n",
    "                'sar_lat': nearest[2],\n",
    "                'sar_lon': nearest[3],\n",
    "                'sar_distance_km': nearest[0]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plots ####\n",
    "\n",
    "# map_object = pl.norsat_plot_uncertainty_ellipses(norsat_data = norsat_data, date_key = date_key)\n",
    "# map_object.save(f'./images/ellipses_map_{date_key}.html')\n",
    "# map_object  # Display the map\n",
    "\n",
    "#object_map = pl.unified_plot(ais_mmsi = time_matching_ais_sar, sar_data = SAR_on_sea, norsat_data = None, date_key = date_key)\n",
    "#object_map.save(f'./images/SAR_AIS_{date_key}_{current_time}.html')\n",
    "\n",
    "#object_map1 = pl.unified_plot(ais_mmsi = None, sar_data = None, norsat_data = norsat_data, interpolated_ais = ais_norsat_interpol, date_key = date_key)\n",
    "#object_map1.save(f'./images/Norsat_AIS_{date_key}_{current_time}.html')\n",
    "\n",
    "def generate_random_color():\n",
    "        r = lambda: random.randint(0, 255)\n",
    "        return '#{:02x}{:02x}{:02x}'.format(r(), r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get unique matches ###\n",
    "def get_unique_shortest_distance_norsat(df):\n",
    "    # Step 1: Group by 'mmsi' and 'sar_id', and select the row with the shortest distance for each group\n",
    "    shortest_distance_df = df.loc[df.groupby(['mmsi', 'norsat_id'])['norsat_distance_km'].idxmin()].reset_index(drop=True)\n",
    "    \n",
    "    # Step 2: Ensure unique 'mmsi' and 'sar_id' by filtering out duplicates\n",
    "    # Sort by distance so we prioritize the smallest distance when removing duplicates\n",
    "    sorted_df = shortest_distance_df.sort_values(by='norsat_distance_km')\n",
    "\n",
    "    # Drop rows where 'mmsi' or 'sar_id' appear more than once\n",
    "    return sorted_df.drop_duplicates(subset='mmsi', keep='first').drop_duplicates(subset='norsat_id', keep='first')\n",
    "\n",
    "def get_unique_shortest_distance_sar(df):\n",
    "    # Step 1: Group by 'mmsi' and 'sar_id', and select the row with the shortest distance for each group\n",
    "    shortest_distance_df = df.loc[df.groupby(['mmsi', 'sar_id'])['sar_distance_km'].idxmin()].reset_index(drop=True)\n",
    "    \n",
    "    # Step 2: Ensure unique 'mmsi' and 'sar_id' by filtering out duplicates\n",
    "    # Sort by distance so we prioritize the smallest distance when removing duplicates\n",
    "    sorted_df = shortest_distance_df.sort_values(by='sar_distance_km')\n",
    "\n",
    "    # Drop rows where 'mmsi' or 'sar_id' appear more than once\n",
    "    return sorted_df.drop_duplicates(subset='mmsi', keep='first').drop_duplicates(subset='sar_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hung = hungarian_method(ais_sar_interpol, sar_data['sar_landmasked'])\n",
    "matched_ships_df = match_ships_to_norsat_nearest_neighbor(ship_dict = ais_norsat_interpol, norsat_data = norsat_data[date_key])\n",
    "\n",
    "sar_data['sar_landmasked'].loc[:, 'sar_id'] = range(1, len(sar_data['sar_landmasked']) + 1)\n",
    "norsat_data[date_key].loc[:,'norsat_id'] = range(1, len(norsat_data[date_key]) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match:\n",
    "norsat_matched_ships_df = match_ships_to_norsat_nearest_neighbor(ship_dict = ais_norsat_interpol, norsat_data = norsat_data[date_key])\n",
    "sar_matched_ships_df = two_nearest_neighbors(ais_sar_interpol, sar_data['sar_landmasked'])\n",
    "\n",
    "# Get only uniques:\n",
    "unique_norsat_df = get_unique_shortest_distance_norsat(norsat_matched_ships_df)\n",
    "unique_sar_df = get_unique_shortest_distance_sar(sar_matched_ships_df)\n",
    "\n",
    "# Threshold for distance\n",
    "unique_sar_df_tresholded = unique_sar_df[unique_sar_df['sar_distance_km'] <= 50.25]\n",
    "unique_norsat_df_tresholded = unique_norsat_df[unique_norsat_df['norsat_distance_km']<= 50.25]\n",
    "\n",
    "# Triple matchings\n",
    "triple_match_df = unique_norsat_df_tresholded.merge(unique_sar_df_tresholded, on=['mmsi'])\n",
    "\n",
    "print(min(norsat_data[date_key]['latitude']),max(norsat_data[date_key]['latitude']))\n",
    "print(min(norsat_data[date_key]['longitude']),max(norsat_data[date_key]['longitude']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable lat and lon #\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import random\n",
    "\n",
    "def generate_random_color():\n",
    "        r = lambda: random.randint(0, 255)\n",
    "        return '#{:02x}{:02x}{:02x}'.format(r(), r(), r())\n",
    "\n",
    "def add_lat_lon_labels(ax, draw_labels=True, label_size=12):\n",
    "    \"\"\"\n",
    "    Adds latitude and longitude labels to a Cartopy map plot.\n",
    "    \n",
    "    Args:\n",
    "        ax (GeoAxes): The Cartopy GeoAxes object to which labels are added.\n",
    "        draw_labels (bool): Whether to draw the latitude and longitude labels.\n",
    "        label_size (int): Font size of the labels.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Add gridlines to the map\n",
    "    gl = ax.gridlines(draw_labels=draw_labels, crs=ccrs.PlateCarree(), linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Customize longitude labels (bottom and top of the map)\n",
    "    gl.xlabels_top = False  # Disable labels at the top\n",
    "    gl.xlabels_bottom = True  # Enable labels at the bottom\n",
    "    gl.xformatter = cticker.LongitudeFormatter()  # Longitude labels\n",
    "    gl.xlabel_style = {'size': label_size, 'rotation': 0}\n",
    "\n",
    "    # Customize latitude labels (left and right of the map)\n",
    "    gl.ylabels_right = False  # Disable labels on the right\n",
    "    gl.ylabels_left = True  # Enable labels on the left\n",
    "    gl.yformatter = cticker.LatitudeFormatter()  # Latitude labels\n",
    "    gl.ylabel_style = {'size': label_size, 'rotation': 0}\n",
    "\n",
    "# Triple match # \n",
    "def plot_triple_matches_on_cartopy(df):\n",
    "    \"\"\"\n",
    "    Visualizes the positions of vessels from AIS data, Norsat data, and SAR data on a Cartopy map. \n",
    "    The function creates markers for each vessel's location and connects them with lines to illustrate relationships.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A pandas DataFrame containing vessel data with latitude and longitude columns for AIS, Norsat, and SAR.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map with vessel locations and connections.\n",
    "    \"\"\"\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Calculate the extent dynamically based on latitude and longitude columns\n",
    "    min_lon = df[['ais_lon_x', 'ais_lon_y', 'norsat_lon', 'sar_lon']].min().min()\n",
    "    max_lon = df[['ais_lon_x', 'ais_lon_y', 'norsat_lon', 'sar_lon']].max().max()\n",
    "    min_lat = df[['ais_lat_x', 'ais_lat_y', 'norsat_lat', 'sar_lat']].min().min()\n",
    "    max_lat = df[['ais_lat_x', 'ais_lat_y', 'norsat_lat', 'sar_lat']].max().max()\n",
    "\n",
    "    # Create a new figure with the European Albers Equal Area projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AlbersEqualArea(central_longitude=10, central_latitude=52, \n",
    "                                                                   standard_parallels=(43, 62)))\n",
    "\n",
    "    # Set the extent of the map dynamically with a small buffer for better visibility\n",
    "    ax.set_extent([min_lon - 0.5, max_lon + 0.5, min_lat - 0.5, max_lat + 0.5], crs=ccrs.PlateCarree())\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "    \n",
    "    # Add coastlines and other geographical features\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "    # Iterate over the rows of the dataframe to plot markers and lines\n",
    "    for _, row in df.iterrows():\n",
    "        # Plot AIS X location (ais_lat_x, ais_lon_x)\n",
    "        ax.plot(row['ais_lon_x'], row['ais_lat_x'], marker='o', color='blue', label='AIS X' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot AIS Y location (ais_lat_y, ais_lon_y)\n",
    "        ax.plot(row['ais_lon_y'], row['ais_lat_y'], marker='o', color='blue', label='AIS Y' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot Norsat location (norsat_lat, norsat_lon)\n",
    "        ax.plot(row['norsat_lon'], row['norsat_lat'], marker='d', color='red', label='Norsat' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot SAR location (sar_lat, sar_lon)\n",
    "        ax.plot(row['sar_lon'], row['sar_lat'], marker='X', color='green', label='SAR' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Draw lines between AIS X and Norsat\n",
    "        ax.plot([row['ais_lon_x'], row['norsat_lon']], [row['ais_lat_x'], row['norsat_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines between AIS Y and SAR\n",
    "        ax.plot([row['ais_lon_y'], row['sar_lon']], [row['ais_lat_y'], row['sar_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines connecting AIS X and AIS Y\n",
    "        ax.plot([row['ais_lon_x'], row['ais_lon_y']], [row['ais_lat_x'], row['ais_lat_y']], color='orange', linestyle='--', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add legend to the map\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Triple matching, matches: {num_matches}')\n",
    "    # Display the map\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# single match #\n",
    "def plot_matches(df):\n",
    "    \"\"\"\n",
    "    Plots matches between AIS and either SAR or Norsat data based on the DataFrame input.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing either SAR or Norsat data with latitude and longitude columns.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine if the DataFrame is for SAR or Norsat based on column names\n",
    "    if 'sar_id' in df.columns:\n",
    "        lat_col = 'sar_lat'\n",
    "        lon_col = 'sar_lon'\n",
    "        target_type = 'SAR'\n",
    "        colors = 'red'\n",
    "        mark = 'd'\n",
    "\n",
    "    elif 'norsat_id' in df.columns:\n",
    "        lat_col = 'norsat_lat'\n",
    "        lon_col = 'norsat_lon'\n",
    "        target_type = 'Norsat'\n",
    "        colors = 'green'\n",
    "        mark = 'x'\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame doesn't contain SAR or Norsat columns\")\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Calculate the extent dynamically based on latitude and longitude columns\n",
    "    min_lon = df[['ais_lon', lon_col]].min().min()\n",
    "    max_lon = df[['ais_lon', lon_col]].max().max()\n",
    "    min_lat = df[['ais_lat', lat_col]].min().min()\n",
    "    max_lat = df[['ais_lat', lat_col]].max().max()\n",
    "\n",
    "    # Create a new figure with the European Albers Equal Area projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AlbersEqualArea(central_longitude=10, central_latitude=52, \n",
    "                                                                   standard_parallels=(43, 62)))\n",
    "\n",
    "    # Set the extent of the map dynamically with a small buffer for better visibility\n",
    "    ax.set_extent([min_lon - 0.5, max_lon + 0.5, min_lat - 0.5, max_lat + 0.5], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "\n",
    "    # Add features to the map\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "    \n",
    "    size=5\n",
    "    # Plot AIS points\n",
    "    ax.scatter(df['ais_lon'], df['ais_lat'], \n",
    "               color='blue', label='AIS', zorder=5, transform=ccrs.PlateCarree(), s = size)\n",
    "\n",
    "    # Plot target points (SAR or Norsat)\n",
    "    ax.scatter(df[lon_col], df[lat_col], \n",
    "               marker = mark, color=colors, label=target_type, zorder=5, transform=ccrs.PlateCarree(), s = size)\n",
    "\n",
    "    # Plot lines between AIS and target (SAR or Norsat)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.plot([row['ais_lon'], row[lon_col]], \n",
    "                [row['ais_lat'], row[lat_col]], \n",
    "                color='black', linestyle='--', alpha=0.6, transform=ccrs.PlateCarree())\n",
    "\n",
    "    \n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f'Matches Between AIS and {target_type}, matches: {num_matches}')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple match # \n",
    "def plot_triple_matches_on_cartopy(df):\n",
    "    \"\"\"\n",
    "    Visualizes the positions of vessels from AIS data, Norsat data, and SAR data on a Cartopy map. \n",
    "    The function creates markers for each vessel's location and connects them with lines to illustrate relationships.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A pandas DataFrame containing vessel data with latitude and longitude columns for AIS, Norsat, and SAR.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map with vessel locations and connections.\n",
    "    \"\"\"\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Calculate the extent dynamically based on latitude and longitude columns\n",
    "    min_lon = df[['ais_lon_x', 'ais_lon_y', 'norsat_lon', 'sar_lon']].min().min()\n",
    "    max_lon = df[['ais_lon_x', 'ais_lon_y', 'norsat_lon', 'sar_lon']].max().max()\n",
    "    min_lat = df[['ais_lat_x', 'ais_lat_y', 'norsat_lat', 'sar_lat']].min().min()\n",
    "    max_lat = df[['ais_lat_x', 'ais_lat_y', 'norsat_lat', 'sar_lat']].max().max()\n",
    "\n",
    "    # Create a new figure with the European Albers Equal Area projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AlbersEqualArea(central_longitude=10, central_latitude=52, \n",
    "                                                                   standard_parallels=(43, 62)))\n",
    "\n",
    "    # Set the extent of the map dynamically with a small buffer for better visibility\n",
    "    ax.set_extent([min_lon - 0.5, max_lon + 0.5, min_lat - 0.5, max_lat + 0.5], crs=ccrs.PlateCarree())\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "    \n",
    "    # Add coastlines and other geographical features\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "    # Iterate over the rows of the dataframe to plot markers and lines\n",
    "    for _, row in df.iterrows():\n",
    "        # Plot AIS X location (ais_lat_x, ais_lon_x)\n",
    "        ax.plot(row['ais_lon_x'], row['ais_lat_x'], marker='o', color='blue', label='AIS X' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot AIS Y location (ais_lat_y, ais_lon_y)\n",
    "        ax.plot(row['ais_lon_y'], row['ais_lat_y'], marker='o', color='blue', label='AIS Y' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot Norsat location (norsat_lat, norsat_lon)\n",
    "        ax.plot(row['norsat_lon'], row['norsat_lat'], marker='d', color='red', label='Norsat' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot SAR location (sar_lat, sar_lon)\n",
    "        ax.plot(row['sar_lon'], row['sar_lat'], marker='X', color='green', label='SAR' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Draw lines between AIS X and Norsat\n",
    "        ax.plot([row['ais_lon_x'], row['norsat_lon']], [row['ais_lat_x'], row['norsat_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines between AIS Y and SAR\n",
    "        ax.plot([row['ais_lon_y'], row['sar_lon']], [row['ais_lat_y'], row['sar_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines connecting AIS X and AIS Y\n",
    "        ax.plot([row['ais_lon_x'], row['ais_lon_y']], [row['ais_lat_x'], row['ais_lat_y']], color='orange', linestyle='--', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add legend to the map\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Triple matching, matches: {num_matches}')\n",
    "    # Display the map\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# single match #\n",
    "def plot_matches(df):\n",
    "    \"\"\"\n",
    "    Plots matches between AIS and either SAR or Norsat data based on the DataFrame input.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing either SAR or Norsat data with latitude and longitude columns.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine if the DataFrame is for SAR or Norsat based on column names\n",
    "    if 'sar_id' in df.columns:\n",
    "        lat_col = 'sar_lat'\n",
    "        lon_col = 'sar_lon'\n",
    "        target_type = 'SAR'\n",
    "        colors = 'red'\n",
    "        mark = 'd'\n",
    "\n",
    "    elif 'norsat_id' in df.columns:\n",
    "        lat_col = 'norsat_lat'\n",
    "        lon_col = 'norsat_lon'\n",
    "        target_type = 'Norsat'\n",
    "        colors = 'green'\n",
    "        mark = 'x'\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame doesn't contain SAR or Norsat columns\")\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Calculate the extent dynamically based on latitude and longitude columns\n",
    "    min_lon = df[['ais_lon', lon_col]].min().min()\n",
    "    max_lon = df[['ais_lon', lon_col]].max().max()\n",
    "    min_lat = df[['ais_lat', lat_col]].min().min()\n",
    "    max_lat = df[['ais_lat', lat_col]].max().max()\n",
    "\n",
    "    # Create a new figure with the European Albers Equal Area projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AlbersEqualArea(central_longitude=10, central_latitude=52, \n",
    "                                                                   standard_parallels=(43, 62)))\n",
    "\n",
    "    # Set the extent of the map dynamically with a small buffer for better visibility\n",
    "    ax.set_extent([min_lon - 0.5, max_lon + 0.5, min_lat - 0.5, max_lat + 0.5], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "\n",
    "    # Add features to the map\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "    \n",
    "    size=5\n",
    "    # Plot AIS points\n",
    "    ax.scatter(df['ais_lon'], df['ais_lat'], \n",
    "               color='blue', label='AIS', zorder=5, transform=ccrs.PlateCarree(), s = size)\n",
    "\n",
    "    # Plot target points (SAR or Norsat)\n",
    "    ax.scatter(df[lon_col], df[lat_col], \n",
    "               marker = mark, color=colors, label=target_type, zorder=5, transform=ccrs.PlateCarree(), s = size)\n",
    "\n",
    "    # Plot lines between AIS and target (SAR or Norsat)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.plot([row['ais_lon'], row[lon_col]], \n",
    "                [row['ais_lat'], row[lat_col]], \n",
    "                color='black', linestyle='--', alpha=0.6, transform=ccrs.PlateCarree())\n",
    "\n",
    "    \n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f'Matches Between AIS and {target_type}, matches: {num_matches}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong point #\n",
    "def plot_wrong_point(df):\n",
    "    \"\"\"\n",
    "    Plots matches between AIS and either SAR or Norsat data based on the DataFrame input.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing either SAR or Norsat data with latitude and longitude columns.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine if the DataFrame is for SAR or Norsat based on column names\n",
    "    if 'sar_id' in df.columns:\n",
    "        lat_col = 'sar_lat'\n",
    "        lon_col = 'sar_lon'\n",
    "        target_type = 'SAR'\n",
    "        colors = 'red'\n",
    "        mark = 'd'\n",
    "\n",
    "    elif 'norsat_id' in df.columns:\n",
    "        lat_col = 'norsat_lat'\n",
    "        lon_col = 'norsat_lon'\n",
    "        target_type = 'Norsat'\n",
    "        colors = 'green'\n",
    "        mark = 'x'\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame doesn't contain SAR or Norsat columns\")\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Define the extent for the map around 70° 12' 50\" N, 23° 12' 0\" E\n",
    "    center_lat = 70.2139  # Approximate latitude of the center location\n",
    "    center_lon = 23.2000  # Approximate longitude of the center location\n",
    "    lat_buffer = .30  # Increase buffer to zoom out more\n",
    "    lon_buffer = .40  # Increase buffer to zoom out more\n",
    "\n",
    "    # Create a new figure with the PlateCarree projection (appropriate for latitude/longitude data)\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Set the extent of the map around the specific location\n",
    "    ax.set_extent([center_lon - lon_buffer, center_lon + lon_buffer, center_lat - lat_buffer, center_lat + lat_buffer], \n",
    "                  crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "\n",
    "    # Add features to the map\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "    \n",
    "    size = 5\n",
    "    # Plot AIS points\n",
    "    ax.scatter(df['ais_lon'], df['ais_lat'], \n",
    "               color='blue', label='AIS', zorder=5, transform=ccrs.PlateCarree(), s=size)\n",
    "\n",
    "    # Plot target points (SAR or Norsat)\n",
    "    ax.scatter(df[lon_col], df[lat_col], \n",
    "               marker=mark, color=colors, label=target_type, zorder=5, transform=ccrs.PlateCarree(), s=size)\n",
    "\n",
    "    # Plot lines between AIS and target (SAR or Norsat)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.plot([row['ais_lon'], row[lon_col]], \n",
    "                [row['ais_lat'], row[lat_col]], \n",
    "                color='black', linestyle='--', alpha=0.6, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    plt.title(f'Matches Between AIS and {target_type}')#, matches: {num_matches}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single match #\n",
    "def plot_matches(df):\n",
    "    \"\"\"\n",
    "    Plots matches between AIS and either SAR or Norsat data based on the DataFrame input.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing either SAR or Norsat data with latitude and longitude columns.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine if the DataFrame is for SAR or Norsat based on column names\n",
    "    if 'sar_id' in df.columns:\n",
    "        lat_col = 'sar_lat'\n",
    "        lon_col = 'sar_lon'\n",
    "        target_type = 'SAR'\n",
    "        colors = 'red'\n",
    "        mark = 'd'\n",
    "\n",
    "    elif 'norsat_id' in df.columns:\n",
    "        lat_col = 'norsat_lat'\n",
    "        lon_col = 'norsat_lon'\n",
    "        target_type = 'Norsat'\n",
    "        colors = 'green'\n",
    "        mark = 'x'\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame doesn't contain SAR or Norsat columns\")\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Calculate the extent dynamically based on latitude and longitude columns\n",
    "    min_lon = df[['ais_lon', lon_col]].min().min()\n",
    "    max_lon = df[['ais_lon', lon_col]].max().max()\n",
    "    min_lat = df[['ais_lat', lat_col]].min().min()\n",
    "    max_lat = df[['ais_lat', lat_col]].max().max()\n",
    "\n",
    "    # Create a new figure with the European Albers Equal Area projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AlbersEqualArea(central_longitude=10, central_latitude=52, \n",
    "                                                                   standard_parallels=(43, 62)))\n",
    "\n",
    "    # Set the extent of the map dynamically with a small buffer for better visibility\n",
    "    ax.set_extent([min_lon - 0.5, max_lon + 0.5, min_lat - 0.5, max_lat + 0.5], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "\n",
    "    # Add features to the map\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "    \n",
    "    size=5\n",
    "    # Plot AIS points\n",
    "    ax.scatter(df['ais_lon'], df['ais_lat'], \n",
    "               color='blue', label='AIS', zorder=5, transform=ccrs.PlateCarree(), s = size)\n",
    "\n",
    "    # Plot target points (SAR or Norsat)\n",
    "    ax.scatter(df[lon_col], df[lat_col], \n",
    "               marker = mark, color=colors, label=target_type, zorder=5, transform=ccrs.PlateCarree(), s = size)\n",
    "\n",
    "    # Plot lines between AIS and target (SAR or Norsat)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.plot([row['ais_lon'], row[lon_col]], \n",
    "                [row['ais_lat'], row[lat_col]], \n",
    "                color='black', linestyle='--', alpha=0.6, transform=ccrs.PlateCarree())\n",
    "\n",
    "    \n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f'Matches Between AIS and {target_type}, matches: {num_matches}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple match # \n",
    "def plot_triple_matches_on_cartopy(df):\n",
    "    \"\"\"\n",
    "    Visualizes the positions of vessels from AIS data, Norsat data, and SAR data on a Cartopy map. \n",
    "    The function creates markers for each vessel's location and connects them with lines to illustrate relationships.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A pandas DataFrame containing vessel data with latitude and longitude columns for AIS, Norsat, and SAR.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map with vessel locations and connections.\n",
    "    \"\"\"\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Calculate the extent dynamically based on latitude and longitude columns\n",
    "    min_lon = df[['ais_lon_x', 'ais_lon_y', 'norsat_lon', 'sar_lon']].min().min()\n",
    "    max_lon = df[['ais_lon_x', 'ais_lon_y', 'norsat_lon', 'sar_lon']].max().max()\n",
    "    min_lat = df[['ais_lat_x', 'ais_lat_y', 'norsat_lat', 'sar_lat']].min().min()\n",
    "    max_lat = df[['ais_lat_x', 'ais_lat_y', 'norsat_lat', 'sar_lat']].max().max()\n",
    "\n",
    "    # Create a new figure with the European Albers Equal Area projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AlbersEqualArea(central_longitude=10, central_latitude=52, \n",
    "                                                                   standard_parallels=(43, 62)))\n",
    "\n",
    "    # Set the extent of the map dynamically with a small buffer for better visibility\n",
    "    ax.set_extent([min_lon - 0.5, max_lon + 0.5, min_lat - 0.5, max_lat + 0.5], crs=ccrs.PlateCarree())\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "    \n",
    "    # Add coastlines and other geographical features\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "    # Iterate over the rows of the dataframe to plot markers and lines\n",
    "    for _, row in df.iterrows():\n",
    "        # Plot AIS X location (ais_lat_x, ais_lon_x)\n",
    "        ax.plot(row['ais_lon_x'], row['ais_lat_x'], marker='o', color='blue', label='AIS X' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot AIS Y location (ais_lat_y, ais_lon_y)\n",
    "        ax.plot(row['ais_lon_y'], row['ais_lat_y'], marker='o', color='blue', label='AIS Y' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot Norsat location (norsat_lat, norsat_lon)\n",
    "        ax.plot(row['norsat_lon'], row['norsat_lat'], marker='d', color='red', label='Norsat' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot SAR location (sar_lat, sar_lon)\n",
    "        ax.plot(row['sar_lon'], row['sar_lat'], marker='X', color='green', label='SAR' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Draw lines between AIS X and Norsat\n",
    "        ax.plot([row['ais_lon_x'], row['norsat_lon']], [row['ais_lat_x'], row['norsat_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines between AIS Y and SAR\n",
    "        ax.plot([row['ais_lon_y'], row['sar_lon']], [row['ais_lat_y'], row['sar_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines connecting AIS X and AIS Y\n",
    "        ax.plot([row['ais_lon_x'], row['ais_lon_y']], [row['ais_lat_x'], row['ais_lat_y']], color='orange', linestyle='--', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add legend to the map\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Triple matching, matches: {num_matches}')\n",
    "    # Display the map\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good match #\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "def plot_good_matches(df):\n",
    "    \"\"\"\n",
    "    Visualizes the good matches between AIS data, Norsat data, and SAR data on a Cartopy map.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A pandas DataFrame containing vessel data with latitude and longitude columns for AIS, Norsat, and SAR.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the map with vessel locations and connections.\n",
    "    \"\"\"\n",
    "\n",
    "    num_matches = len(df)\n",
    "\n",
    "    # Define the extent for the map around 69°46'28.8\"N, 19°10'35.7\"E\n",
    "    center_lat = 69.7747  # Latitude of the new center location\n",
    "    center_lon = 19.1766  # Longitude of the new center location\n",
    "    lat_buffer = 0.7  # Buffer to control zoom level (adjust for desired zoom)\n",
    "    lon_buffer = 0.7  # Buffer to control zoom level (adjust for desired zoom)\n",
    "\n",
    "    # Create a new figure with the PlateCarree projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Set the extent of the map around the new specific location\n",
    "    ax.set_extent([center_lon - lon_buffer, center_lon + lon_buffer, center_lat - lat_buffer, center_lat + lat_buffer], \n",
    "                  crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Add latitude and longitude labels\n",
    "    add_lat_lon_labels(ax)\n",
    "\n",
    "    # Add coastlines and other geographical features\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "    ax.add_feature(cfeature.LAKES, color='lightblue')\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "    # Iterate over the rows of the dataframe to plot markers and lines\n",
    "    for _, row in df.iterrows():\n",
    "        # Plot AIS X location (ais_lat_x, ais_lon_x)\n",
    "        ax.plot(row['ais_lon_x'], row['ais_lat_x'], marker='o', color='blue', label='AIS (RF)' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot AIS Y location (ais_lat_y, ais_lon_y)\n",
    "        ax.plot(row['ais_lon_y'], row['ais_lat_y'], marker='o', color='blue', label='AIS (SAR)' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot Norsat location (norsat_lat, norsat_lon)\n",
    "        ax.plot(row['norsat_lon'], row['norsat_lat'], marker='X', color='green', label='Norsat' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot SAR location (sar_lat, sar_lon)\n",
    "        ax.plot(row['sar_lon'], row['sar_lat'], marker='d', color='red', label='SAR' if _ == 0 else \"\", transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Draw lines between AIS X and Norsat\n",
    "        ax.plot([row['ais_lon_x'], row['norsat_lon']], [row['ais_lat_x'], row['norsat_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines between AIS Y and SAR\n",
    "        ax.plot([row['ais_lon_y'], row['sar_lon']], [row['ais_lat_y'], row['sar_lat']], color='blue', linestyle='--', transform=ccrs.PlateCarree())\n",
    "        # Draw lines connecting AIS X and AIS Y\n",
    "        ax.plot([row['ais_lon_x'], row['ais_lon_y']], [row['ais_lat_x'], row['ais_lat_y']], color='orange', linestyle='--', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add legend to the map\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Triple matches, AIS, SAR and RF')\n",
    "    # Display the map\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram with PDF #\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_rms_distance(df, distance_col):\n",
    "    \"\"\"\n",
    "    Calculate the RMS for a given distance column in the DataFrame.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(df[distance_col] ** 2))\n",
    "\n",
    "def plot_distance_histogram_with_pdf(df, distance_col, title):\n",
    "    \"\"\"\n",
    "    Create a histogram with PDF (kde) of the distance between targets and annotate with RMS.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the distance column\n",
    "    - distance_col: Column name for distances\n",
    "    - title: Title of the plot\n",
    "    \"\"\"\n",
    "    # Calculate RMS for the distance\n",
    "    rms_distance = calculate_rms_distance(df, distance_col)\n",
    "\n",
    "    # Number of bins equal to the number of data points to ensure all distances are visible\n",
    "    num_bins = len(df[distance_col])\n",
    "\n",
    "    # Create a histogram with count on y-axis and PDF overlay\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[distance_col], kde=True, color='blue', bins=num_bins, stat=\"count\", label='Distance with PDF')\n",
    "\n",
    "    # Annotate the RMS on the plot\n",
    "    plt.axvline(rms_distance, color='red', linestyle='--', label=f'RMS = {rms_distance:.4f}')\n",
    "    plt.text(rms_distance, plt.ylim()[1]*0.8, f'RMS: {rms_distance:.4f}', color='red', fontsize=12, ha='center')\n",
    "\n",
    "    # Titles and labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Distance (km)')\n",
    "    plt.ylabel('Count')  # Set y-axis label to 'Count'\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_triple_matches_on_cartopy(triple_match_df)\n",
    "\n",
    "#plot_matches(unique_sar_df_tresholded)\n",
    "#plot_matches(unique_norsat_df_tresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium\n",
    "folium_map_sar = pl.plot_matches_on_folium(unique_sar_df_tresholded)\n",
    "folium_map_norsat = pl.plot_matches_on_folium(unique_norsat_df_tresholded) \n",
    "folium_map = pl.plot_triple_matches_on_folium(triple_match_df)\n",
    "\n",
    "folium_map_sar.save(f\"./images/matches_map_sar{current_time}.html\")\n",
    "folium_map_norsat.save(f\"./images/matches_map_norsat{current_time}.html\")\n",
    "\n",
    "folium_map.save(f\"./images/triple_matches_map_5_{current_time}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_wrong_point(unique_sar_df_tresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_good_matches(triple_match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for SAR vs AIS distance\n",
    "plot_distance_histogram_with_pdf(unique_sar_df_tresholded, 'sar_distance_km', 'Histogram of SAR vs AIS Distance with PDF and RMS')\n",
    "\n",
    "# Plot for Norsat vs AIS distance\n",
    "plot_distance_histogram_with_pdf(unique_norsat_df_tresholded, 'norsat_distance_km', 'Histogram of Norsat vs AIS Distance with PDF and RMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for SAR vs AIS distance\n",
    "plot_distance_histogram_with_pdf(unique_sar_df_tresholded, 'sar_distance_km', 'Histogram of SAR vs AIS Distance with PDF and RMS')\n",
    "\n",
    "# Plot for Norsat vs AIS distance\n",
    "plot_distance_histogram_with_pdf(unique_norsat_df_tresholded, 'norsat_distance_km', 'Histogram of Norsat vs AIS Distance with PDF and RMS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beskriv med \"egen fornuft\" fejlkilder, for at begynder og overveje hvordan de kan mitigeres, fjernes eller accepteres.\n",
    "\n",
    "Real sar opløsning 22 meter, men oversampler for til 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOR TESTING #\n",
    "    @staticmethod\n",
    "    def apply_dbscan_clustering(df1: pd.DataFrame, df2: pd.DataFrame, ids : List[str], sources : List[str] ,eps: float, min_samples: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Applies DBSCAN clustering to two DataFrames based on their spatial coordinates.\n",
    "        \n",
    "        Parameters:\n",
    "        - df1: First DataFrame containing data with columns ['id', 'latitude', 'longitude'].\n",
    "        - df2: Second DataFrame containing data with columns ['id', 'latitude', 'longitude'].\n",
    "        - eps: Maximum distance between two samples for them to be considered as in the same neighborhood (in kilometers).\n",
    "        - min_samples: The number of samples in a neighborhood for a point to be considered a core point.\n",
    "\n",
    "        Returns:\n",
    "        - Combined DataFrame with cluster labels.\n",
    "        \"\"\"\n",
    "        df1 = df1.copy()\n",
    "        df2 = df2.copy()\n",
    "        df1.rename(columns={ids[0]: 'id'}, inplace=True)\n",
    "        df2.rename(columns={ids[1]: 'id'}, inplace=True)\n",
    "\n",
    "        # Ensure the DataFrames contain 'latitude' and 'longitude' columns        \n",
    "        if not {'latitude', 'longitude'}.issubset(df1.columns) or not {'latitude', 'longitude'}.issubset(df2.columns):\n",
    "                if {'int_latitude', 'int_longitude'}.issubset(df1.columns):\n",
    "                    df1.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "                elif {'int_latitude', 'int_longitude'}.issubset(df2.columns):\n",
    "                    df2.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "                else:\n",
    "                    raise ValueError(\"Input DataFrames must contain 'latitude' and 'longitude' columns.\")\n",
    "\n",
    "        # Combine the two DataFrames, adding a source column to differentiate them\n",
    "        combined_data = pd.concat([\n",
    "            df1[['id', 'latitude', 'longitude']].assign(source=sources[0]),\n",
    "            df2[['id', 'latitude', 'longitude']].assign(source=sources[1])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # Extract the coordinates for clustering\n",
    "        latitudes = combined_data['latitude'].values\n",
    "        longitudes = combined_data['longitude'].values\n",
    "\n",
    "        # Create the Haversine distance matrix between all points\n",
    "        distances = np.zeros((len(latitudes), len(latitudes)))\n",
    "        for i in range(len(latitudes)):\n",
    "            for j in range(len(latitudes)):\n",
    "                distances[i, j] = ClusteringMatcher.haversine_distance(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "\n",
    "        # Convert the distance matrix to radians for DBSCAN with Haversine distance\n",
    "        eps_rad = eps \n",
    "\n",
    "        # Apply DBSCAN with precomputed distance matrix\n",
    "        clustering = DBSCAN(eps=eps_rad, min_samples=min_samples, metric='precomputed')\n",
    "        labels = clustering.fit_predict(distances)\n",
    "\n",
    "        # Assign cluster labels to the combined data\n",
    "        combined_data['cluster'] = labels\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "        print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "        print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "            \n",
    "        return combined_data\n",
    "\n",
    "    @staticmethod\n",
    "    def HAM_clustering2(df1: pd.DataFrame, df2: pd.DataFrame, ids: List[str], sources: List[str], eps: float = 0.5, min_samples: int = 1) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Matches df1 and df2 data within each cluster using the Hungarian algorithm.\n",
    "\n",
    "        Parameters:\n",
    "        - df1: First DataFrame containing [id1_col, 'latitude', 'longitude'] and other necessary columns.\n",
    "        - df2: Second DataFrame containing [id2_col, 'latitude', 'longitude'] and other necessary columns.\n",
    "        - ids: List of identifier column names for df1 and df2 respectively (e.g., ['mmsi', 'sar_id']).\n",
    "        - sources: List of source names to assign for df1 and df2 respectively (e.g., ['ais', 'sar']).\n",
    "        - eps: Maximum distance between two samples for them to be considered as in the same neighborhood (DBSCAN parameter).\n",
    "        - min_samples: The number of samples in a neighborhood for a point to be considered a core point (DBSCAN parameter).\n",
    "\n",
    "        Returns:\n",
    "        - A DataFrame containing the matched results.\n",
    "        \"\"\"        \n",
    "\n",
    "        df1 = df1.copy()\n",
    "        df2 = df2.copy()\n",
    "        \n",
    "        # Ensure the DataFrames contain 'latitude' and 'longitude' columns        \n",
    "        if not {'latitude', 'longitude'}.issubset(df1.columns) or not {'latitude', 'longitude'}.issubset(df2.columns):\n",
    "            if {'int_latitude', 'int_longitude'}.issubset(df1.columns):\n",
    "                df1.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "            elif {'int_latitude', 'int_longitude'}.issubset(df2.columns):\n",
    "                df2.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "            else:\n",
    "                raise ValueError(\"Input DataFrames must contain 'latitude' and 'longitude' columns.\")\n",
    "\n",
    "        # Apply DBSCAN clustering\n",
    "        combined_data = ClusteringMatcher.apply_dbscan_clustering(df1, df2, ids, sources, eps, min_samples)\n",
    "\n",
    "        # Initialize a list to store all matches\n",
    "        all_matches = []\n",
    "\n",
    "        # Get unique cluster labels\n",
    "        unique_clusters = combined_data['cluster'].unique()\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            if cluster == -1:\n",
    "                # Skip noise points (cluster label -1 in DBSCAN)\n",
    "                continue\n",
    "\n",
    "            # Extract points within the current cluster\n",
    "            cluster_data = combined_data[combined_data['cluster'] == cluster]\n",
    "            cluster_df1 = cluster_data[cluster_data['source'] == sources[0]]\n",
    "            cluster_df2 = cluster_data[cluster_data['source'] == sources[1]]\n",
    "\n",
    "            # Ensure there are both df1 and df2 points in the cluster\n",
    "            if len(cluster_df1) > 0 and len(cluster_df2) > 0:\n",
    "                # Extract coordinates for df1 and df2 in the current cluster\n",
    "                df1_coords = cluster_df1[['latitude', 'longitude']].to_numpy()\n",
    "                df2_coords = cluster_df2[['latitude', 'longitude']].to_numpy()\n",
    "\n",
    "                # Create cost matrix using Haversine distance\n",
    "                cost_matrix = ClusteringMatcher.haversine_distance(\n",
    "                    df1_coords[:, 0][:, None], df1_coords[:, 1][:, None], \n",
    "                    df2_coords[:, 0][None, :], df2_coords[:, 1][None, :]\n",
    "                )\n",
    "\n",
    "                # Apply Hungarian algorithm\n",
    "                ship_indices, df2_indices = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "                # Create matches for the current cluster\n",
    "                for ship_idx, df2_idx in zip(ship_indices, df2_indices):\n",
    "                    # Extract match details\n",
    "                    df1_id = cluster_df1.iloc[ship_idx]['id']\n",
    "                    df1_lat = cluster_df1.iloc[ship_idx]['latitude']\n",
    "                    df1_lon = cluster_df1.iloc[ship_idx]['longitude']\n",
    "                    df2_id = cluster_df2.iloc[df2_idx]['id']\n",
    "                    df2_lat = cluster_df2.iloc[df2_idx]['latitude']\n",
    "                    df2_lon = cluster_df2.iloc[df2_idx]['longitude']\n",
    "                    distance_km = cost_matrix[ship_idx, df2_idx]\n",
    "\n",
    "                    # Create a match record with the required columns\n",
    "                    match = {\n",
    "                        ids[0]: df1_id.astype(int),\n",
    "                        'df1_lat': df1_lat,\n",
    "                        'df1_lon': df1_lon,\n",
    "                        ids[1]: df2_id.astype(int),\n",
    "                        'df2_lat': df2_lat,\n",
    "                        'df2_lon': df2_lon,\n",
    "                        'distance_km': distance_km\n",
    "                    }\n",
    "                    all_matches.append(match)\n",
    "\n",
    "        # Convert all matches to a DataFrame\n",
    "        return pd.DataFrame(all_matches)\n",
    "\n",
    "    @staticmethod\n",
    "    def NNM_clustering2(df1: pd.DataFrame, df2: pd.DataFrame, ids: list, sources: list, eps: float = 0.5, min_samples: int = 1) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Matches df1 and df2 data using nearest neighbor matching after applying DBSCAN clustering.\n",
    "\n",
    "        Parameters:\n",
    "        - df1 (pd.DataFrame): First DataFrame containing [ids[0], 'latitude', 'longitude'] and other necessary columns.\n",
    "        - df2 (pd.DataFrame): Second DataFrame containing [ids[1], 'latitude', 'longitude'] and other necessary columns.\n",
    "        - ids (list): List containing the identifier column names for df1 and df2 respectively (e.g., ['mmsi', 'sar_id']).\n",
    "        - sources (list): List containing the source names to assign for df1 and df2 respectively (e.g., ['ais', 'sar']).\n",
    "        - eps (float): Maximum distance between two samples for them to be considered in the same neighborhood (DBSCAN parameter).\n",
    "        - min_samples (int): The number of samples in a neighborhood for a point to be considered a core point (DBSCAN parameter).\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame containing the matched points and their distances, ensuring unique matches.\n",
    "        \"\"\"\n",
    "        def lat_lon_to_cartesian(lat, lon):\n",
    "            \"\"\"\n",
    "            Convert latitude and longitude to Cartesian coordinates.\n",
    "\n",
    "            Args:\n",
    "                lat (np.ndarray): Array of latitudes in radians.\n",
    "                lon (np.ndarray): Array of longitudes in radians.\n",
    "\n",
    "            Returns:\n",
    "                np.ndarray: Cartesian coordinates as (x, y, z).\n",
    "            \"\"\"\n",
    "            R = 6371.0  # Radius of the Earth in kilometers\n",
    "            x = R * np.cos(lat) * np.cos(lon)\n",
    "            y = R * np.cos(lat) * np.sin(lon)\n",
    "            z = R * np.sin(lat)\n",
    "            return np.vstack([x, y, z]).T\n",
    "\n",
    "        # Create copies of the dataframes to avoid modifying the original DataFrames\n",
    "        df1 = df1.copy()\n",
    "        df2 = df2.copy()\n",
    "        # Ensure the DataFrames contain 'latitude' and 'longitude' columns        \n",
    "        if not {'latitude', 'longitude'}.issubset(df1.columns) or not {'latitude', 'longitude'}.issubset(df2.columns):\n",
    "            if {'int_latitude', 'int_longitude'}.issubset(df1.columns):\n",
    "                df1.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "            elif {'int_latitude', 'int_longitude'}.issubset(df2.columns):\n",
    "                df2.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "            else:\n",
    "                raise ValueError(\"Input DataFrames must contain 'latitude' and 'longitude' columns.\")\n",
    "\n",
    "        # Assign source labels\n",
    "        df1.loc[:, 'source'] = sources[0]\n",
    "        df2.loc[:, 'source'] = sources[1]\n",
    "\n",
    "        # Apply DBSCAN clustering\n",
    "        combined_df = ClusteringMatcher.apply_dbscan_clustering(df1, df2, ids, sources, eps, min_samples)\n",
    "\n",
    "        # Initialize a list to store all matches\n",
    "        all_matches = []\n",
    "\n",
    "        # Get unique cluster labels\n",
    "        unique_clusters = combined_df['cluster'].unique()\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            if cluster == -1:\n",
    "                continue\n",
    "\n",
    "            # Extract points in the current cluster for df1 and df2 separately\n",
    "            cluster_df1 = combined_df[(combined_df['cluster'] == cluster) & (combined_df['source'] == sources[0])]\n",
    "            cluster_df2 = combined_df[(combined_df['cluster'] == cluster) & (combined_df['source'] == sources[1])]\n",
    "\n",
    "            # Ensure there are points from both df1 and df2 in the cluster\n",
    "            if len(cluster_df1) > 0 and len(cluster_df2) > 0:\n",
    "                # Convert latitude and longitude to radians for nearest neighbor search\n",
    "                df1_cartesian = lat_lon_to_cartesian(\n",
    "                    np.radians(cluster_df1['latitude'].values), np.radians(cluster_df1['longitude'].values)\n",
    "                )\n",
    "                df2_cartesian = lat_lon_to_cartesian(\n",
    "                    np.radians(cluster_df2['latitude'].values), np.radians(cluster_df2['longitude'].values)\n",
    "                )\n",
    "\n",
    "                # Build KDTree for df2 points in the cluster\n",
    "                tree = cKDTree(df2_cartesian)\n",
    "\n",
    "                # Find nearest neighbors for each df1 point in the cluster\n",
    "                _, indices = tree.query(df1_cartesian)\n",
    "\n",
    "                # Create a DataFrame to store matches in the current cluster\n",
    "                cluster_matches = pd.DataFrame({\n",
    "                    ids[0]: cluster_df1['id'].values.astype(int),\n",
    "                    'df1_lat': cluster_df1['latitude'].values,\n",
    "                    'df1_lon': cluster_df1['longitude'].values,\n",
    "                    ids[1]: cluster_df2.iloc[indices]['id'].values.astype(int),\n",
    "                    'df2_lat': cluster_df2.iloc[indices]['latitude'].values,\n",
    "                    'df2_lon': cluster_df2.iloc[indices]['longitude'].values,\n",
    "                    'distance_km': ClusteringMatcher.haversine_distance(\n",
    "                        cluster_df1['latitude'].values, cluster_df1['longitude'].values,\n",
    "                        cluster_df2.iloc[indices]['latitude'].values, cluster_df2.iloc[indices]['longitude'].values\n",
    "                    ),\n",
    "                    'cluster': cluster,\n",
    "                    'df2_index': cluster_df2.index[indices]  # Track df2 indices for unique matching\n",
    "                })\n",
    "\n",
    "                # Remove duplicate df2 matches to ensure unique matching within the cluster\n",
    "                cluster_matches = cluster_matches.sort_values('distance_km').drop_duplicates(subset=['df2_index'], keep='first')\n",
    "                # Remove rows where df1_id has multiple entries (df1 should have unique matches)\n",
    "                cluster_matches = cluster_matches.drop_duplicates(subset=[ids[0]], keep='first')\n",
    "                # Drop the helper 'df2_index' column\n",
    "                cluster_matches = cluster_matches.drop(columns='df2_index')\n",
    "\n",
    "                # Append cluster matches to the overall list of matches\n",
    "                all_matches.append(cluster_matches)\n",
    "\n",
    "        # Concatenate all cluster matches into a single DataFrame\n",
    "        final_matches = pd.concat(all_matches, ignore_index=True)\n",
    "\n",
    "        return final_matches\n",
    "    \n",
    "    @staticmethod\n",
    "    def Machine_clustering2(df1, df2, ids, sources, eps=7, min_samples=2, model_path = r'C:\\Users\\abelt\\OneDrive\\Dokumenter\\GitHub\\Ship_datafusion\\models\\model_epoch.pth'):\n",
    "        \"\"\"\n",
    "        Matches AIS and SAR data by applying DBSCAN clustering followed by the Hungarian algorithm.\n",
    "        \n",
    "        Parameters:\n",
    "        - df1: DataFrame containing the AIS points.\n",
    "        - df2: DataFrame containing the SAR points.\n",
    "        - ids: List of unique identifiers for df1 and df2. Example: ['mmsi', 'sar_id'].\n",
    "        - sources: List of sources for df1 and df2. Example: ['ais', 'sar'].\n",
    "        - eps: The maximum distance between two samples for them to be considered as in the same neighborhood (for DBSCAN).\n",
    "        - min_samples: The number of points required to form a cluster (for DBSCAN).\n",
    "        - model_path: Path to the model for the Hungarian algorithm (optional).\n",
    "        \n",
    "        Returns:\n",
    "        - matching_df: DataFrame containing matched points between df1 and df2.\n",
    "        \"\"\"\n",
    "        df1_c = df1.copy()\n",
    "        df2_c = df2.copy()\n",
    "        # Ensure the DataFrames contain 'latitude' and 'longitude' columns        \n",
    "        if not {'latitude', 'longitude'}.issubset(df1_c.columns) or not {'latitude', 'longitude'}.issubset(df2_c.columns):\n",
    "            if {'int_latitude', 'int_longitude'}.issubset(df1_c.columns):\n",
    "                df1_c.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "            elif {'int_latitude', 'int_longitude'}.issubset(df2_c.columns):\n",
    "                df2_c.rename(columns={'int_latitude': 'latitude', 'int_longitude': 'longitude'}, inplace=True)\n",
    "            else:\n",
    "                raise ValueError(\"Input DataFrames must contain 'latitude' and 'longitude' columns.\")\n",
    "        \n",
    "        # Apply DBSCAN clustering (using a placeholder function)\n",
    "        clustered_df = ClusteringMatcher.apply_dbscan_clustering(df2_c, df2_c, ids=ids, sources=sources, eps=eps, min_samples=min_samples)\n",
    "\n",
    "        # Get unique cluster labels\n",
    "        unique_clusters = clustered_df['cluster'].unique()\n",
    "\n",
    "        # Initialize a list to store all matches across clusters\n",
    "        all_matches = []\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            if cluster == -1:\n",
    "                # Skip noise points (cluster label -1 in DBSCAN)\n",
    "                continue\n",
    "\n",
    "            # Extract points within the current cluster\n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster]\n",
    "            cluster_df1 = cluster_data[cluster_data['source'] == sources[0]]  # AIS points\n",
    "            cluster_df2 = cluster_data[cluster_data['source'] == sources[1]]  # SAR points\n",
    "\n",
    "            # Ensure there are both df1 and df2 points in the cluster\n",
    "            if len(cluster_df1) > 0 and len(cluster_df2) > 0:\n",
    "                # Extract coordinates for df1 and df2 in the current cluster\n",
    "                df1_coords = cluster_df1[['latitude', 'longitude']]\n",
    "                df2_coords = cluster_df2[['latitude', 'longitude']]\n",
    "                \n",
    "                # Apply Hungarian algorithm to find optimal matches\n",
    "                idx1, idx2 = ClusteringMatcher.compute_distance_matrix_with_hungarian(model_path, df1_coords, df2_coords)\n",
    "                \n",
    "                # Convert the tensors to numpy arrays or lists for indexing pandas DataFrames\n",
    "                ship_indices = idx1.numpy()\n",
    "                df2_indices = idx2.numpy()\n",
    "\n",
    "                # Create matches for the current cluster\n",
    "                for ship_idx, df2_idx in zip(ship_indices, df2_indices):\n",
    "                    \n",
    "                    # Extract match details from df1 and df2\n",
    "                    df1_match = cluster_df1.iloc[ship_idx]\n",
    "                    df2_match = cluster_df2.iloc[df2_idx]\n",
    "\n",
    "                    # Extract relevant columns\n",
    "                    df1_id = df1_match['id']  # e.g., 'mmsi'\n",
    "                    df1_lat = df1_match['latitude']\n",
    "                    df1_lon = df1_match['longitude']\n",
    "                    df2_id = df2_match['id']  # e.g., 'sar_id'\n",
    "                    df2_lat = df2_match['latitude']\n",
    "                    df2_lon = df2_match['longitude']\n",
    "                    \n",
    "                    # You can also add distance or other matching criteria if you have them\n",
    "                    # distance_km = cost_matrix[ship_idx, df2_idx]\n",
    "\n",
    "                    # Create a match record as a dictionary\n",
    "                    match = {\n",
    "                        ids[0]: df1_id,  # e.g., 'mmsi'\n",
    "                        'df1_lat': df1_lat,\n",
    "                        'df1_lon': df1_lon,\n",
    "                        ids[1]: df2_id,  # e.g., 'sar_id'\n",
    "                        'df2_lat': df2_lat,\n",
    "                        'df2_lon': df2_lon,\n",
    "                        # Uncomment this if you calculate distance\n",
    "                        # 'distance_km': distance_km\n",
    "                    }\n",
    "\n",
    "                    # Append the match to the list of all matches\n",
    "                    all_matches.append(match)\n",
    "\n",
    "        # Convert the list of matches into a DataFrame\n",
    "        return pd.DataFrame(all_matches)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafusion_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
